//ppt 작동 시작//

- slide 1

안녕하세요~~!!
Self-Organizing Map에 관한 발표를 시작하겠습니다.
데이터 안의 각각의 개체들이
어느 그룹에 속해있는지 분류해보는 것을 clustering이라 하는데
이와 관련해서는 Logistic Regression, K-nearest neighbor,
Support vector machine, Discriminant Analysis, Decision tree 등 
여러 종류의 통계적인 방법론들이 존재합니다.
Self-Organizing Map도 이 방법론들 중의 하나입니다.

- slide 2

발표는 다음과 같은 순서로 진행될 것입니다. (내용설명 ~~~)

- slide 3

먼저 Self-Organizing Map, SOM에 관해서 간략하게 살펴보겠습니다.
SOM은 대뇌피질과 시각피질을 modeling한 인공신경망의 일종이라고 할 수 있습니다.
데이터들을 입력했을 때 출력 node들 중 다른 출력 node와 비교해서 가장 강하게
반응하는 node를 더욱 더 강하게 반응하게끔 반복적으로 학습시키는 것이
주된 원리라고 할 수 있으며,
해석하기 어려운 고차원 data를 저차원으로 변환시켜서 보는 사람으로 하여금
좀 더 알아보기 쉽게 표현할 수 있도록 해주는 통계적인 방법론이라고 할 수 있습니다.
일반적으로 저차원의 기준은 2차원으로 잡는 것이 관례입니다.

- slide 4

SOM은 핀란드 태생의 scientist인 Teuvo Kohonen에 의해 1982년에 처음으로 
세상에 소개되었으며 그의 이름을 따서 Kohonen Map이라고도 불립니다.
SOM의 가장 큰 특징은 대부분의 신경망 알고리즘이 지도학습방법을 사용하는 것과는 대조적으로
자율학습방법과 경쟁학습방법을 사용한다는 것이라고 할 수 있습니다.

- slide 5

앞 슬라이드에서도 말씀드렸듯이 SOM을 처음 발견한 사람은
핀란드 출신의 Teuvo Kohonen이라는 scientist입니다.
그는 주로 Artificial Neural Network, 즉 인공신경망과 관련된 분야에서
많은 연구활동을 하고 있으며,
특히 지금 제가 설명하고 있는 자기조직화지도, SOM과 관련된 연구가 
큰 업적으로 평가받고 있습니다.

- slide 6

이제부터 SOM이 어떤 식으로 작동하는 지 살펴보겠습니다.
고차원의 데이터는 일반적으로 분석이 어렵기 때문에 
알아보기 쉽도록 차원의 수를 낮추어서 변환시키게 되는데 이 때 SOM을 사용하면 효과적입니다.
이 그림은 바로 그 logic을 설명하고 있는 것입니다.
고차원의 X 데이터를 저차원의 Y 데이터로 변환시키고 있음을 확인할 수 있습니다.

- slide 7

SOM의 핵심적인 원리는 고차원의 복잡한 data를 저차원의 영역에 적절하게 
그물망을 덮는 것처럼 변형시키는 것입니다. 단, 주어진 data의 특성을 왜곡시키지 않는 범위 하에서 
그물망을 만들도록 해야 할 것이며 그물망을 제대로 만들기 위해서는 해당 data를 대표하는 
핵심적인 패턴을 찾는 것이 중요하다고 할 수 있겠습니다.

- slide 8

SOM에서 주로 쓰이는 방법은 competitive learning이라 불리는 경쟁적 학습방법입니다.
이 방법의 핵심은 일반적으로 거리를 나타낼 때 자주 사용하는 Euclidean distance를 측정하여 
data를 잘 나타낸다고 여겨지는 주요패턴을 찾는 것이 point라고 할 수 있습니다.

- slide 9

다음 그림은 SOM의 기본적인 원리를 잘 나타내고 있습니다.
파란색 영역은 training data의 분포이며 그 위에 떠있는 그물망은 분석하고자 하는 실제 data를 
나타냅니다. 첫번째 그림과 같이 SOM node는 임의의 데이터 공간에 배치되어 있으며 
노란색으로 표시된 부분은 training data의 영역과 가장 가까운 node를 표시한 것인데 
이 node를 소위 Best matching unit, BMU라고 부릅니다. 이 node를 기준으로 하여 
주어진 고차원의 data 그물망을 저차원의 training data 영역에 덮어 씌우게 됩니다. 
이러한 과정을 반복추정법이라고 불리우는 Jackknife method를 이용하여 반복실시하게 되고 
결과적으로 축약된 data는 마지막 그림과 같이 주어진 training data의 분포에 근사하게 되어
SOM에 의한 model을 완성하게 됩니다.

- slide 10

다음 수식은 앞에서 설명한 SOM의 원리를 간략하게 표현한 것입니다.
앞 슬라이드에서도 설명했듯이 SOM의 핵심은 training data의 영역과 가장 가까운 
Best matching unit을 찾는 것이라고 할 수 있습니다.

- slide 11

이전 slide의 내용을 설명하자면 다음과 같습니다. (계속 이어서 설명~~) 

- slide 12

앞서 말씀드렸듯이 일반적으로 SOM에서는
고차원의 데이터를 2차원으로 변환시켜서 분석하는 것이 관례입니다.
이를 위해서 데이터 전체를 설명할 수 있는 root인 2가지 주요 패턴을 찾게 되는데
이를 보통 principal component eigenvectors라고 부릅니다.

- slide 13

다음 그림은 자기구조화지도에 의해 만들어지는 신경망의 특징을 표현한 그림입니다.
데이터 내에 있는 개체들의 특성을 파악하기 위해
면밀하게 분석하고 있는 과정을 상징적으로 보여주고 있습니다.

- slide 14

SOM을 활용하게 되면 한눈에 파악하기 어려운 데이터를 개체분석을 통해서
알아보기 용이하도록 정렬할 수 있습니다.
이 그림에서는 여러 사람들의 얼굴의 특징을 분석하여 4개의 그룹으로
분류하는 것을 나타낸 것인데 이러한 과정을 통해서
data를 보다 더 쉽게 이해할 수 있을 것입니다.

- slide 15

SOM은 여러 분야에서 두루 쓰이고 있는 통계적방법론입니다.
지금 보시는 그림은 미국 의회와 관련된 투표의 결과를 
SOM을 통해 패턴분석을 해서 2차원으로 나타낸 것입니다.
여기에서 빨간색으로 표시된 부분은 공화당, 파란색으로 표시된 부분은
민주당을 지지하는 비율이라고 이해하시면 됩니다.
첫번째 그림은 주어진 변수들을 사용해 최종적으로 분류한 결과이고.
나머지 그림들은 각각의 설명변수들에 의해 어떻게 패턴을 분류하고 있는지 보여주고 있습니다. 
이 결과들을 적절하게 조합해서 첫번째 그림과 같은 최종 결과물을 얻게 됩니다. 
뒤 slide에서 다른 data를 가지고 R을 통해 시연해 볼 예정입니다.

- slide 16

SOM은 복잡한 아미노산의 구조를 보다 더 쉽게 이해할 수 있도록
표현할 경우에도 사용가능합니다.
아미노산의 구조는 매우 복잡하기 때문에 그대로 놓고 이해한다는 것은
매우 어려우므로 구조를 간단하게 표현하면 
연구활동 시 불필요한 시간을 줄일 수 있을 것입니다.

- slide 17

SOM은 우리가 살아가고 있는 사회의 특성을 알아보기 위해서 실시하는
사회조사에서도 유용하게 사용되고 있습니다.
사람 각 개개인의 특성은 수많은 변수들의 조합에 의해서
표현됩니다. 그렇기 때문에 SOM을 통하여 수많은 변수들 중
강한 영향력을 행사하고 있는 나이 또는 성별 등의 몇개의 변수를 뽑아서 살펴보면
보다 더 효율적으로 자료를 분석할 수 있습니다.

- slide 18

지금부터는 R을 사용하여 실제 데이터를 가지고 SOM을 구현하는 과정을
살펴보도록 하겠습니다.
전체적인 과정을 간단하게 설명하자면 먼저 주어진 데이터를
training data와 test data로 분류한 다음
training data을 이용하여 SOM 분석을 통한 model을 작성하고
test data에 있는 개체들의 class를 예측하게 됩니다.
처음으로 사용하게 될 데이터는 패키지 kohonen에 내장되어있는
와인과 관련된 데이터입니다. R을 이용하여 SOM을 구현하기 위해서는
패키지 kohonen을 반드시 설치해야 하며 
각각의 변수들의 단위의 scale이 다를 수 있으므로
training data와 test data에 대한 centering과 scaling 작업을
먼저 실시해야 합니다.
이 모의실험에서는 training data와 test data의 크기를 각각
120, 77로 정하였습니다.

- slide 19

지금 보시는 table은 SOM을 통해 만들어진 model이 어떻게 test data를
분류했는지를 보여주는 것입니다.
위의 table에서 세로축은 실제 wine의 class를, 가로축은 SOM을 이용하여
예측한 wine의 class를 나타냅니다. 결과를 보면 총 57개의 test data들 중 
실제 class가 2인데 3으로 잘못 예측한 자료가 3개임을 알 수 있습니다. 
결과적으로 오분류율은 5.3% 가 되고 예측의 결과가 
그리 나쁘지 않았다고 말할 수 있겠습니다.

- slide 20

다음 그래프는 training data에서 가장 가까운 개체들에 대한 평균거리가 
어떤 식으로 변하고 있는지를 보여주고 있습니다. 
SOM에서는 이 평균거리를 통하여 데이터를 저차원으로 변환시켜서 model을 만들고 
이에 따라 새로운 데이터에 대해서 예측도 실시하게 됩니다.

- slide 21

다음 그림은 SOM을 통하여 각 wine 별로 나타난 변수값에 따라 어떤 식으로
modeling을 실시했는지 보여주는 fan diagram입니다.
각 변수들마다 색을 다르게 하여 구별할 수 있도록 하였고
변수값들이 어떻게 분포되어 있는지도 확인할 수 있습니다.

- slide 22

그리고 다음과 같이 각 wine이 속해있는 class에 따라서
어떤 식으로 modeling을 실시했는지 보여주는 그래프도
R에서는 제공을 하고 있습니다. 여기에서 숫자 1,2,3은
3가지의 wine group을 의미하며 앞 슬라이드에서의 결과와 유사한 방법으로
그룹별로 색을 다르게 하여 구별이 용이하게 하고 있습니다.

- slide 23

지금 보시는 그래프는 training data가 어떤 식으로 분포되어있는지
알아볼 수 있도록 하고 있습니다.
색이 진할 수록 개체들의 개수가 적다는 것을 쉽게 알 수 있습니다.

- slide 24

다음 그림은 SOM을 통하여 실시한 분류결과를 각 그룹별로 다른 색을
사용하여 표현한 것입니다.
동그라미 안에 표시된 모양들이 실제 개체가 속해있는 그룹을
표시한 것이기 때문에 이 그림을 통해서
SOM을 이용한 예측이 얼마나 잘 되었는지 확인할 수 있습니다.

- slide 25

이제부터는 인구조사와 관련해서 SOM이 활용된 예를 살펴보고자 합니다.
분석에 사용한 데이터는 2011년 아일랜드의 Dublin 지역과 관련이 있으며
15가지 주제와 관련된 767가지의 변수들로 구성되어 있습니다.
이 변수들 중 임의로 선택된 일부 변수들에 의하여
18,488 곳의 작은 지역들을 어떻게 분류하는지 살펴보고자 하며
아래의 링크를 통해 해당 data와 R code를 다운로드할 수 있습니다.

- slide 26

그 이전에 몇가지 작업이 필요합니다.
이 데이터는 해당하는 사람들의 수로 구성되어있기 때문에
평균이나 비율 등과 같은 비교가 가능한 통계량을 계산하여 첨부하는 작업을 실시하였으며,
분석이 가능하도록 순위화 되어있는 범주형 변수는 모두 수치화시켰습니다.

- slide 27

그 다음 각각의 지역에 해당하는 특징들을 수치화하여 계산 후 첨부하여
원하는 data 생성작업을 마무리했습니다.
분석하고자 하는 data는 각 지역의 고유번호와 13개의 특징을 나타내는
변수들을 포함하여 총 14개의 변수들로 구성되어있습니다.

- slide 28

이후 얻어진 분석용 데이터를 기반으로 SOM 기법 구현을 위한
training data를 생성하고 model 구축을 실시하였습니다.
Model을 만드는 데 선택한 변수는 평균 나이,
평균 교육수준, 평균 보유 차량수, 미취업률 의 총 4가지를 선택하였습니다.
지도의 크기는 20 by 20의 6각형 위상공간으로 설정하였고,
평균거리는 약 0.113 정도로 나타났습니다.

- slide 29

결과적으로 다음과 같은 그림들을 얻을 수 있었습니다.
왼쪽 그림은 가장 가까운 개체들의 평균 거리가 어떻게 변하는지를 보여주며
오른쪽 그림은 해당하는 node의 개수를 색깔별로 나타낸 것입니다.

- slide 30

이제 다음 그림을 보도록 하겠습니다.
왼쪽 그림은 계산된 거리에 따라 진한 정도를 다르게 해본 것입니다.
색이 진할 수록 가까운 거리이기 때문에
연관성이 높은 개체가 있을 가능성이 많게 됩니다.
오른쪽 그림은 선택된 변수에 따라 어떻게 modeling을
실시했는지 보여주는 fan diagram입니다.

- slide 31

이 diagram은 변수들이 training data에 어떤 식으로
분포되어있는지 보여주고 있습니다.
각 변수 별로 색을 다르게 입히고 해당하는 수에 따라 크기를
다르게 하였기 때문에 각각 어떤 특징들을 나타내고 있는지
대략적으로 확인할 수 있습니다.

- slide 32

지금 보시는 두 그림은 평균 교육수준과 미취업률이
training data에 어떻게 분포하고 있는지를 보여주고 있습니다.
차가운 색을 띠고 있는 부분이 수치가 낮은 것이며
뜨거운 색을 띠고 있는 부분이 수치가 높은 것이라고
생각하시면 됩니다.

- slide 33

지금부터 보시게 될 4가지 그림은
특정변수가 training data와 얼마나 연관성이 있는지를
나타내는 겁니다.
먼저 평균나이와 임대비율은 수치가 낮은 곳이
더 많은 것으로 보아 연관성이 많이 없는 것으로 보여집니다.

- slide 34

하지만 인터넷 사용률과 평균 건강측도는 
수치가 높은 곳이 더 많기 때문에 연관성이 많은 변수라고 봐도
무방할 것입니다.
어떠한 data를 잘 설명하는 변수를 제대로 선택하는 것이
분석에 있어서 중요하다는 것을 시사하는 대목이라 할 수 있겠습니다.

- slide 35

이제 본격적으로 SOM을 통해서 얻은 model을 통해
실제적인 clustering을 실시해보도록 하겠습니다.
군집을 나눌 때 가장 중요한 점은 군집끼리는 서로 영향을
미치지 않도록 만드는 것입니다. 즉 다른 군집 안에 있는 개체는
서로 독립이어야 한다는 내용입니다.
이를 바탕으로 왼쪽의 그래프를 통해 군집끼리의 연관성을 나타내는
Within cluster sum of squares, WCSS의 감소량의 변화가 크게 줄어드는 부분이 6이라는 것을
확인할 수 있었습니다. 
따라서 군집의 개수를 6으로 결정하였습니다.

- slide 36

이를 통해서 다음과 같은 결과를 얻을 수 있었습니다.
이 결과를 통해 각각의 군집에 대한 특징들을 잡을 수 있습니다.
예를 들어서 빨간색에 해당하는 군집은
평균교육수준은 높지만 평균나이와 평균 보유차량수, 그리고
미취업률은 낮음을 알 수 있습니다.
그에 반해 초록색에 해당하는 군집은 평균나이와
평균 보유 차량수는 높고 평균 교육수준과 미취업률은
낮음을 알 수 있습니다.

- slide 37

마지막으로 실제 Dublin 지역을 나타내는 지도 위에
SOM에 의한 clustering의 결과를 mapping해봤습니다.
앞의 결과에 해당하는 내용을 시각적으로
한눈에 알아볼 수 있겠습니다.

- slide 38

마지막으로 SOM의 장단점에 관해서 간략하게 언급하고
발표를 마치고자 합니다.
Self-Organizing Map의 장점은 다른 방법론들에 비해 직관적이라는 것입니다.
그렇기 때문에 소비자에 관한 세분화된 profile을 작성하는데 사용할 수 있으며,
비교적 간단한 algorithm의 이점을 살려서 
일반인들에게 결과를 설명하기 쉬운 편입니다.

- slide 39

하지만 분석하고자 하는 데이터가 반드시 
깨끗하게 정렬되어 있어야 하고 수치만을 포함하고 있어야 실행이 가능하다는
단점도 존재합니다.
또한 한꺼번에 많은 수의 변수들을 2차원의 평면에
표현하기 어려울 때가 종종 발생한다는 한계점도 있습니다.

- slide 40

이상으로 Self-Organizing Map에 관한 발표를 모두 마치겠습니다.
감사합니다.  






